{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "WARNING:tensorflow:From <ipython-input-2-2e82a26757ae>:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, usually either \"0\" or \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"   \n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu,True)#动态分配gpu别让tf一下占满"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = fetch_openml('iris',version= 1,return_X_y= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X (150, 4)\n",
      "shape of Y (150,)\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]]\n",
      "['Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa']\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of X\",X.shape)\n",
    "print(\"shape of Y\",Y.shape)\n",
    "print(X[:10])\n",
    "print(Y[:10])\n",
    "# 1. sepal length in cm\n",
    "# 2. sepal width in cm\n",
    "# 3. petal length in cm\n",
    "# 4. petal width in cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 3)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "Y = Y.reshape(len(Y),-1)#需要reshape成列向量\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(Y)\n",
    "labels = enc.transform(Y).toarray()#需要三步有点麻烦\n",
    "print (labels.shape)\n",
    "print(labels[:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX,testX,trainY,testY = train_test_split(X,labels,train_size = 120,test_size = 30,random_state = 233)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of trainX (120, 4)\n",
      "shape of trainY (120, 3)\n",
      "[[4.8 3.  1.4 0.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [6.8 3.  5.5 2.1]]\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of trainX\",trainX.shape)\n",
    "print(\"shape of trainY\",trainY.shape)\n",
    "print(trainX[:20])\n",
    "print(trainY[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyModel(inputs):\n",
    "    x = layers.Dense(10,activation=\"tanh\")(inputs)\n",
    "    x = layers.Dense(8,activation=\"tanh\")(x)\n",
    "    x = layers.Dense(6,activation=\"tanh\")(x)\n",
    "    output = layers.Dense(3,activation=\"softmax\")(x)\n",
    "    model = tf.keras.Model(inputs = inputs,outputs = output)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 213\n",
      "Trainable params: 213\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel(tf.keras.Input(shape=(4)))\n",
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(lr = 0.04, beta_1=0.9, beta_2=0.999)\n",
    "sc = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer= adam, loss= sc, metrics=['accuracy','AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96 samples, validate on 24 samples\n",
      "Epoch 1/150\n",
      "96/96 [==============================] - 1s 6ms/sample - loss: 1.1076 - accuracy: 0.3021 - AUC: 0.5337 - val_loss: 1.0936 - val_accuracy: 0.5833 - val_AUC: 0.6059\n",
      "Epoch 2/150\n",
      "96/96 [==============================] - 0s 129us/sample - loss: 1.0551 - accuracy: 0.7083 - AUC: 0.7071 - val_loss: 1.0938 - val_accuracy: 0.5000 - val_AUC: 0.5751\n",
      "Epoch 3/150\n",
      "96/96 [==============================] - 0s 130us/sample - loss: 1.0157 - accuracy: 0.6771 - AUC: 0.7008 - val_loss: 1.0196 - val_accuracy: 0.5833 - val_AUC: 0.6463\n",
      "Epoch 4/150\n",
      "96/96 [==============================] - 0s 121us/sample - loss: 0.9281 - accuracy: 0.7083 - AUC: 0.7595 - val_loss: 0.9667 - val_accuracy: 0.5833 - val_AUC: 0.6936\n",
      "Epoch 5/150\n",
      "96/96 [==============================] - 0s 136us/sample - loss: 0.8707 - accuracy: 0.7083 - AUC: 0.8199 - val_loss: 0.9379 - val_accuracy: 0.5833 - val_AUC: 0.8229\n",
      "Epoch 6/150\n",
      "96/96 [==============================] - 0s 115us/sample - loss: 0.8367 - accuracy: 0.7083 - AUC: 0.9129 - val_loss: 0.9088 - val_accuracy: 0.5833 - val_AUC: 0.8815\n",
      "Epoch 7/150\n",
      "96/96 [==============================] - 0s 125us/sample - loss: 0.7981 - accuracy: 0.7083 - AUC: 0.9315 - val_loss: 0.8467 - val_accuracy: 0.6250 - val_AUC: 0.9049\n",
      "Epoch 8/150\n",
      "96/96 [==============================] - 0s 128us/sample - loss: 0.7537 - accuracy: 0.8229 - AUC: 0.9662 - val_loss: 0.7846 - val_accuracy: 0.7917 - val_AUC: 0.9440\n",
      "Epoch 9/150\n",
      "96/96 [==============================] - 0s 106us/sample - loss: 0.7057 - accuracy: 0.9583 - AUC: 0.9902 - val_loss: 0.6928 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 10/150\n",
      "96/96 [==============================] - 0s 148us/sample - loss: 0.6677 - accuracy: 0.9688 - AUC: 0.9962 - val_loss: 0.7012 - val_accuracy: 0.9167 - val_AUC: 0.9874\n",
      "Epoch 11/150\n",
      "96/96 [==============================] - 0s 122us/sample - loss: 0.6411 - accuracy: 0.9688 - AUC: 0.9971 - val_loss: 0.6336 - val_accuracy: 0.9583 - val_AUC: 0.9991\n",
      "Epoch 12/150\n",
      "96/96 [==============================] - 0s 120us/sample - loss: 0.6216 - accuracy: 0.9688 - AUC: 0.9983 - val_loss: 0.6997 - val_accuracy: 0.8333 - val_AUC: 0.9796\n",
      "Epoch 13/150\n",
      "96/96 [==============================] - 0s 104us/sample - loss: 0.6219 - accuracy: 0.9479 - AUC: 0.9955 - val_loss: 0.5917 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 14/150\n",
      "96/96 [==============================] - 0s 138us/sample - loss: 0.6004 - accuracy: 0.9688 - AUC: 0.9988 - val_loss: 0.6370 - val_accuracy: 0.9167 - val_AUC: 0.9931\n",
      "Epoch 15/150\n",
      "96/96 [==============================] - 0s 119us/sample - loss: 0.5983 - accuracy: 0.9688 - AUC: 0.9977 - val_loss: 0.5874 - val_accuracy: 0.9583 - val_AUC: 0.9991\n",
      "Epoch 16/150\n",
      "96/96 [==============================] - 0s 113us/sample - loss: 0.5944 - accuracy: 0.9688 - AUC: 0.9985 - val_loss: 0.6349 - val_accuracy: 0.9167 - val_AUC: 0.9931\n",
      "Epoch 17/150\n",
      "96/96 [==============================] - 0s 110us/sample - loss: 0.5944 - accuracy: 0.9688 - AUC: 0.9867 - val_loss: 0.7107 - val_accuracy: 0.8333 - val_AUC: 0.9666\n",
      "Epoch 18/150\n",
      "96/96 [==============================] - 0s 122us/sample - loss: 0.6122 - accuracy: 0.9375 - AUC: 0.9826 - val_loss: 0.5765 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 19/150\n",
      "96/96 [==============================] - 0s 124us/sample - loss: 0.6020 - accuracy: 0.9479 - AUC: 0.9978 - val_loss: 0.7158 - val_accuracy: 0.8333 - val_AUC: 0.9440\n",
      "Epoch 20/150\n",
      "96/96 [==============================] - 0s 100us/sample - loss: 0.6354 - accuracy: 0.9167 - AUC: 0.9763 - val_loss: 0.6198 - val_accuracy: 0.9167 - val_AUC: 0.9961\n",
      "Epoch 21/150\n",
      "96/96 [==============================] - 0s 151us/sample - loss: 0.5777 - accuracy: 0.9792 - AUC: 0.9937 - val_loss: 0.6923 - val_accuracy: 0.8750 - val_AUC: 0.9106\n",
      "Epoch 22/150\n",
      "96/96 [==============================] - 0s 113us/sample - loss: 0.6692 - accuracy: 0.8854 - AUC: 0.9344 - val_loss: 0.5672 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 23/150\n",
      "96/96 [==============================] - 0s 110us/sample - loss: 0.5774 - accuracy: 0.9792 - AUC: 0.9950 - val_loss: 0.8585 - val_accuracy: 0.6667 - val_AUC: 0.8207\n",
      "Epoch 24/150\n",
      "96/96 [==============================] - 0s 110us/sample - loss: 0.6607 - accuracy: 0.8750 - AUC: 0.9484 - val_loss: 0.6370 - val_accuracy: 0.9167 - val_AUC: 0.9779\n",
      "Epoch 25/150\n",
      "96/96 [==============================] - 0s 134us/sample - loss: 0.5772 - accuracy: 0.9792 - AUC: 0.9899 - val_loss: 0.6409 - val_accuracy: 0.9167 - val_AUC: 0.9761\n",
      "Epoch 26/150\n",
      "96/96 [==============================] - 0s 139us/sample - loss: 0.6522 - accuracy: 0.9062 - AUC: 0.9473 - val_loss: 0.5693 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 27/150\n",
      "96/96 [==============================] - 0s 118us/sample - loss: 0.6191 - accuracy: 0.9271 - AUC: 0.9762 - val_loss: 0.8060 - val_accuracy: 0.7500 - val_AUC: 0.8459\n",
      "Epoch 28/150\n",
      "96/96 [==============================] - 0s 113us/sample - loss: 0.6430 - accuracy: 0.9167 - AUC: 0.9427 - val_loss: 0.8854 - val_accuracy: 0.6667 - val_AUC: 0.7413\n",
      "Epoch 29/150\n",
      "96/96 [==============================] - 0s 125us/sample - loss: 0.6732 - accuracy: 0.8750 - AUC: 0.9245 - val_loss: 0.5705 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 30/150\n",
      "96/96 [==============================] - 0s 135us/sample - loss: 0.6212 - accuracy: 0.9271 - AUC: 0.9746 - val_loss: 0.6725 - val_accuracy: 0.8750 - val_AUC: 0.9314\n",
      "Epoch 31/150\n",
      "96/96 [==============================] - 0s 108us/sample - loss: 0.6704 - accuracy: 0.8750 - AUC: 0.9467 - val_loss: 0.5742 - val_accuracy: 0.9583 - val_AUC: 0.9991\n",
      "Epoch 32/150\n",
      "96/96 [==============================] - 0s 138us/sample - loss: 0.5767 - accuracy: 0.9792 - AUC: 0.9839 - val_loss: 0.7860 - val_accuracy: 0.7500 - val_AUC: 0.9028\n",
      "Epoch 33/150\n",
      "96/96 [==============================] - 0s 123us/sample - loss: 0.6414 - accuracy: 0.9062 - AUC: 0.9495 - val_loss: 0.7244 - val_accuracy: 0.8333 - val_AUC: 0.9219\n",
      "Epoch 34/150\n",
      "96/96 [==============================] - 0s 167us/sample - loss: 0.6046 - accuracy: 0.9479 - AUC: 0.9753 - val_loss: 0.5623 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 35/150\n",
      "96/96 [==============================] - 0s 144us/sample - loss: 0.5872 - accuracy: 0.9688 - AUC: 0.9987 - val_loss: 0.5545 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 36/150\n",
      "96/96 [==============================] - 0s 167us/sample - loss: 0.5915 - accuracy: 0.9583 - AUC: 0.9910 - val_loss: 0.5669 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 37/150\n",
      "96/96 [==============================] - 0s 153us/sample - loss: 0.5845 - accuracy: 0.9688 - AUC: 0.9836 - val_loss: 0.5968 - val_accuracy: 0.9583 - val_AUC: 0.9974\n",
      "Epoch 38/150\n",
      "96/96 [==============================] - 0s 151us/sample - loss: 0.5833 - accuracy: 0.9688 - AUC: 0.9839 - val_loss: 0.5925 - val_accuracy: 0.9583 - val_AUC: 0.9991\n",
      "Epoch 39/150\n",
      "96/96 [==============================] - 0s 155us/sample - loss: 0.5827 - accuracy: 0.9688 - AUC: 0.9840 - val_loss: 0.5693 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 40/150\n",
      "96/96 [==============================] - 0s 146us/sample - loss: 0.5770 - accuracy: 0.9792 - AUC: 0.9912 - val_loss: 0.5580 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 41/150\n",
      "96/96 [==============================] - 0s 142us/sample - loss: 0.5803 - accuracy: 0.9688 - AUC: 0.9914 - val_loss: 0.5892 - val_accuracy: 0.9583 - val_AUC: 0.9991\n",
      "Epoch 42/150\n",
      "96/96 [==============================] - 0s 153us/sample - loss: 0.5810 - accuracy: 0.9688 - AUC: 0.9840 - val_loss: 0.6181 - val_accuracy: 0.9167 - val_AUC: 0.9965\n",
      "Epoch 43/150\n",
      "96/96 [==============================] - 0s 119us/sample - loss: 0.5846 - accuracy: 0.9688 - AUC: 0.9837 - val_loss: 0.6336 - val_accuracy: 0.9167 - val_AUC: 0.9926\n",
      "Epoch 44/150\n",
      "96/96 [==============================] - 0s 145us/sample - loss: 0.5866 - accuracy: 0.9688 - AUC: 0.9836 - val_loss: 0.6198 - val_accuracy: 0.9167 - val_AUC: 0.9965\n",
      "Epoch 45/150\n",
      "96/96 [==============================] - 0s 114us/sample - loss: 0.5841 - accuracy: 0.9688 - AUC: 0.9838 - val_loss: 0.5980 - val_accuracy: 0.9583 - val_AUC: 0.9974\n",
      "Epoch 46/150\n",
      "96/96 [==============================] - 0s 120us/sample - loss: 0.5831 - accuracy: 0.9688 - AUC: 0.9839 - val_loss: 0.5723 - val_accuracy: 0.9583 - val_AUC: 0.9991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/150\n",
      "96/96 [==============================] - 0s 115us/sample - loss: 0.5763 - accuracy: 0.9792 - AUC: 0.9916 - val_loss: 0.5543 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 48/150\n",
      "96/96 [==============================] - 0s 164us/sample - loss: 0.5895 - accuracy: 0.9583 - AUC: 0.9913 - val_loss: 0.5554 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 49/150\n",
      "96/96 [==============================] - 0s 122us/sample - loss: 0.5891 - accuracy: 0.9583 - AUC: 0.9912 - val_loss: 0.5918 - val_accuracy: 0.9583 - val_AUC: 0.9991\n",
      "Epoch 50/150\n",
      "96/96 [==============================] - 0s 110us/sample - loss: 0.5818 - accuracy: 0.9688 - AUC: 0.9840 - val_loss: 0.5656 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 51/150\n",
      "96/96 [==============================] - 0s 113us/sample - loss: 0.5755 - accuracy: 0.9792 - AUC: 0.9915 - val_loss: 0.5541 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 52/150\n",
      "96/96 [==============================] - 0s 109us/sample - loss: 0.5928 - accuracy: 0.9583 - AUC: 0.9908 - val_loss: 0.5549 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 53/150\n",
      "96/96 [==============================] - 0s 117us/sample - loss: 0.5814 - accuracy: 0.9688 - AUC: 0.9838 - val_loss: 0.6253 - val_accuracy: 0.9167 - val_AUC: 0.9961\n",
      "Epoch 54/150\n",
      "96/96 [==============================] - 0s 120us/sample - loss: 0.5932 - accuracy: 0.9583 - AUC: 0.9836 - val_loss: 0.6327 - val_accuracy: 0.9167 - val_AUC: 0.9926\n",
      "Epoch 55/150\n",
      "96/96 [==============================] - 0s 114us/sample - loss: 0.5847 - accuracy: 0.9688 - AUC: 0.9838 - val_loss: 0.5597 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 56/150\n",
      "96/96 [==============================] - 0s 105us/sample - loss: 0.5959 - accuracy: 0.9583 - AUC: 0.9906 - val_loss: 0.5541 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 57/150\n",
      "96/96 [==============================] - 0s 129us/sample - loss: 0.5877 - accuracy: 0.9583 - AUC: 0.9984 - val_loss: 0.6031 - val_accuracy: 0.9583 - val_AUC: 0.9974\n",
      "Epoch 58/150\n",
      "96/96 [==============================] - 0s 119us/sample - loss: 0.5840 - accuracy: 0.9688 - AUC: 0.9837 - val_loss: 0.6536 - val_accuracy: 0.9167 - val_AUC: 0.9583\n",
      "Epoch 59/150\n",
      "96/96 [==============================] - 0s 106us/sample - loss: 0.6025 - accuracy: 0.9479 - AUC: 0.9755 - val_loss: 0.6469 - val_accuracy: 0.9167 - val_AUC: 0.9592\n",
      "Epoch 60/150\n",
      "96/96 [==============================] - 0s 118us/sample - loss: 0.5945 - accuracy: 0.9583 - AUC: 0.9759 - val_loss: 0.5615 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 61/150\n",
      "96/96 [==============================] - 0s 135us/sample - loss: 0.5994 - accuracy: 0.9583 - AUC: 0.9903 - val_loss: 0.5590 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 62/150\n",
      "96/96 [==============================] - 0s 144us/sample - loss: 0.5744 - accuracy: 0.9792 - AUC: 0.9915 - val_loss: 0.6256 - val_accuracy: 0.9167 - val_AUC: 0.9957\n",
      "Epoch 63/150\n",
      "96/96 [==============================] - 0s 130us/sample - loss: 0.5848 - accuracy: 0.9688 - AUC: 0.9837 - val_loss: 0.6574 - val_accuracy: 0.9167 - val_AUC: 0.9583\n",
      "Epoch 64/150\n",
      "96/96 [==============================] - 0s 132us/sample - loss: 0.6016 - accuracy: 0.9479 - AUC: 0.9755 - val_loss: 0.6162 - val_accuracy: 0.9167 - val_AUC: 0.9965\n",
      "Epoch 65/150\n",
      "96/96 [==============================] - 0s 125us/sample - loss: 0.5872 - accuracy: 0.9688 - AUC: 0.9837 - val_loss: 0.5544 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 66/150\n",
      "96/96 [==============================] - 0s 135us/sample - loss: 0.5876 - accuracy: 0.9583 - AUC: 0.9910 - val_loss: 0.5772 - val_accuracy: 0.9583 - val_AUC: 0.9991\n",
      "Epoch 67/150\n",
      "96/96 [==============================] - 0s 130us/sample - loss: 0.5837 - accuracy: 0.9688 - AUC: 0.9913 - val_loss: 0.6590 - val_accuracy: 0.9167 - val_AUC: 0.9583\n",
      "Epoch 68/150\n",
      "96/96 [==============================] - 0s 116us/sample - loss: 0.5989 - accuracy: 0.9479 - AUC: 0.9756 - val_loss: 0.6617 - val_accuracy: 0.9167 - val_AUC: 0.9583\n",
      "Epoch 69/150\n",
      "96/96 [==============================] - 0s 133us/sample - loss: 0.5964 - accuracy: 0.9583 - AUC: 0.9756 - val_loss: 0.6231 - val_accuracy: 0.9167 - val_AUC: 0.9965\n",
      "Epoch 70/150\n",
      "96/96 [==============================] - 0s 127us/sample - loss: 0.5837 - accuracy: 0.9688 - AUC: 0.9837 - val_loss: 0.5595 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 71/150\n",
      "96/96 [==============================] - 0s 134us/sample - loss: 0.5766 - accuracy: 0.9792 - AUC: 0.9914 - val_loss: 0.5535 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 72/150\n",
      "96/96 [==============================] - 0s 139us/sample - loss: 0.5864 - accuracy: 0.9583 - AUC: 0.9909 - val_loss: 0.5532 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 73/150\n",
      "96/96 [==============================] - 0s 131us/sample - loss: 0.5849 - accuracy: 0.9688 - AUC: 0.9912 - val_loss: 0.5686 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 74/150\n",
      "96/96 [==============================] - 0s 134us/sample - loss: 0.5788 - accuracy: 0.9688 - AUC: 0.9917 - val_loss: 0.5632 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 75/150\n",
      "96/96 [==============================] - 0s 128us/sample - loss: 0.5774 - accuracy: 0.9792 - AUC: 0.9916 - val_loss: 0.5530 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 76/150\n",
      "96/96 [==============================] - 0s 129us/sample - loss: 0.6012 - accuracy: 0.9479 - AUC: 0.9830 - val_loss: 0.6286 - val_accuracy: 0.9167 - val_AUC: 0.9965\n",
      "Epoch 77/150\n",
      "96/96 [==============================] - 0s 111us/sample - loss: 0.6185 - accuracy: 0.9375 - AUC: 0.9585 - val_loss: 0.6348 - val_accuracy: 0.9167 - val_AUC: 0.9670\n",
      "Epoch 78/150\n",
      "96/96 [==============================] - 0s 111us/sample - loss: 0.6342 - accuracy: 0.9062 - AUC: 0.9724 - val_loss: 0.5883 - val_accuracy: 0.9583 - val_AUC: 0.9991\n",
      "Epoch 79/150\n",
      "96/96 [==============================] - 0s 112us/sample - loss: 0.5822 - accuracy: 0.9688 - AUC: 0.9841 - val_loss: 0.7871 - val_accuracy: 0.7500 - val_AUC: 0.8542\n",
      "Epoch 80/150\n",
      "96/96 [==============================] - 0s 98us/sample - loss: 0.6334 - accuracy: 0.9167 - AUC: 0.9504 - val_loss: 0.7857 - val_accuracy: 0.7500 - val_AUC: 0.8542\n",
      "Epoch 81/150\n",
      "96/96 [==============================] - 0s 120us/sample - loss: 0.6215 - accuracy: 0.9271 - AUC: 0.9662 - val_loss: 0.6238 - val_accuracy: 0.9167 - val_AUC: 0.9957\n",
      "Epoch 82/150\n",
      "96/96 [==============================] - 0s 114us/sample - loss: 0.5902 - accuracy: 0.9583 - AUC: 0.9834 - val_loss: 0.5530 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 83/150\n",
      "96/96 [==============================] - 0s 104us/sample - loss: 0.5900 - accuracy: 0.9583 - AUC: 0.9910 - val_loss: 0.5539 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 84/150\n",
      "96/96 [==============================] - 0s 125us/sample - loss: 0.5789 - accuracy: 0.9792 - AUC: 0.9916 - val_loss: 0.6190 - val_accuracy: 0.9167 - val_AUC: 0.9965\n",
      "Epoch 85/150\n",
      "96/96 [==============================] - 0s 115us/sample - loss: 0.5951 - accuracy: 0.9583 - AUC: 0.9834 - val_loss: 0.6326 - val_accuracy: 0.9167 - val_AUC: 0.9653\n",
      "Epoch 86/150\n",
      "96/96 [==============================] - 0s 101us/sample - loss: 0.5825 - accuracy: 0.9688 - AUC: 0.9839 - val_loss: 0.5529 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 87/150\n",
      "96/96 [==============================] - 0s 121us/sample - loss: 0.5855 - accuracy: 0.9688 - AUC: 0.9989 - val_loss: 0.5925 - val_accuracy: 0.9583 - val_AUC: 0.9974\n",
      "Epoch 88/150\n",
      "96/96 [==============================] - 0s 116us/sample - loss: 0.6133 - accuracy: 0.9375 - AUC: 0.9809 - val_loss: 0.6330 - val_accuracy: 0.9167 - val_AUC: 0.9965\n",
      "Epoch 89/150\n",
      "96/96 [==============================] - 0s 97us/sample - loss: 0.6214 - accuracy: 0.9167 - AUC: 0.9802 - val_loss: 0.6242 - val_accuracy: 0.9167 - val_AUC: 0.9965\n",
      "Epoch 90/150\n",
      "96/96 [==============================] - 0s 119us/sample - loss: 0.5965 - accuracy: 0.9583 - AUC: 0.9831 - val_loss: 0.8788 - val_accuracy: 0.6667 - val_AUC: 0.8203\n",
      "Epoch 91/150\n",
      "96/96 [==============================] - 0s 107us/sample - loss: 0.6812 - accuracy: 0.8646 - AUC: 0.9307 - val_loss: 0.8852 - val_accuracy: 0.6667 - val_AUC: 0.7665\n",
      "Epoch 92/150\n",
      "96/96 [==============================] - 0s 114us/sample - loss: 0.6904 - accuracy: 0.8542 - AUC: 0.9168 - val_loss: 0.7821 - val_accuracy: 0.7500 - val_AUC: 0.8785\n",
      "Epoch 93/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 130us/sample - loss: 0.6233 - accuracy: 0.9271 - AUC: 0.9514 - val_loss: 0.6065 - val_accuracy: 0.9583 - val_AUC: 0.9974\n",
      "Epoch 94/150\n",
      "96/96 [==============================] - 0s 121us/sample - loss: 0.5891 - accuracy: 0.9583 - AUC: 0.9914 - val_loss: 0.5561 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 95/150\n",
      "96/96 [==============================] - 0s 124us/sample - loss: 0.6023 - accuracy: 0.9479 - AUC: 0.9976 - val_loss: 0.5684 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 96/150\n",
      "96/96 [==============================] - 0s 124us/sample - loss: 0.6013 - accuracy: 0.9375 - AUC: 0.9899 - val_loss: 0.5593 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 97/150\n",
      "96/96 [==============================] - 0s 137us/sample - loss: 0.5873 - accuracy: 0.9688 - AUC: 0.9837 - val_loss: 0.6747 - val_accuracy: 0.8750 - val_AUC: 0.9557\n",
      "Epoch 98/150\n",
      "96/96 [==============================] - 0s 137us/sample - loss: 0.6031 - accuracy: 0.9479 - AUC: 0.9752 - val_loss: 0.7500 - val_accuracy: 0.7917 - val_AUC: 0.9141\n",
      "Epoch 99/150\n",
      "96/96 [==============================] - 0s 128us/sample - loss: 0.6204 - accuracy: 0.9375 - AUC: 0.9733 - val_loss: 0.6845 - val_accuracy: 0.8333 - val_AUC: 0.9792\n",
      "Epoch 100/150\n",
      "96/96 [==============================] - 0s 119us/sample - loss: 0.5964 - accuracy: 0.9479 - AUC: 0.9833 - val_loss: 0.5722 - val_accuracy: 0.9583 - val_AUC: 0.9991\n",
      "Epoch 101/150\n",
      "96/96 [==============================] - 0s 121us/sample - loss: 0.5816 - accuracy: 0.9792 - AUC: 0.9989 - val_loss: 0.5796 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 102/150\n",
      "96/96 [==============================] - 0s 125us/sample - loss: 0.6074 - accuracy: 0.9375 - AUC: 0.9884 - val_loss: 0.5826 - val_accuracy: 0.9583 - val_AUC: 0.9991\n",
      "Epoch 103/150\n",
      "96/96 [==============================] - 0s 133us/sample - loss: 0.6106 - accuracy: 0.9271 - AUC: 0.9959 - val_loss: 0.5603 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 104/150\n",
      "96/96 [==============================] - 0s 133us/sample - loss: 0.5774 - accuracy: 0.9792 - AUC: 0.9988 - val_loss: 0.6091 - val_accuracy: 0.9167 - val_AUC: 0.9965\n",
      "Epoch 105/150\n",
      "96/96 [==============================] - 0s 123us/sample - loss: 0.5871 - accuracy: 0.9583 - AUC: 0.9836 - val_loss: 0.6346 - val_accuracy: 0.9167 - val_AUC: 0.9896\n",
      "Epoch 106/150\n",
      "96/96 [==============================] - 0s 142us/sample - loss: 0.5905 - accuracy: 0.9583 - AUC: 0.9834 - val_loss: 0.6083 - val_accuracy: 0.9167 - val_AUC: 0.9965\n",
      "Epoch 107/150\n",
      "96/96 [==============================] - 0s 134us/sample - loss: 0.5819 - accuracy: 0.9688 - AUC: 0.9837 - val_loss: 0.5719 - val_accuracy: 0.9583 - val_AUC: 0.9991\n",
      "Epoch 108/150\n",
      "96/96 [==============================] - 0s 133us/sample - loss: 0.5829 - accuracy: 0.9688 - AUC: 0.9911 - val_loss: 0.5587 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 109/150\n",
      "96/96 [==============================] - 0s 135us/sample - loss: 0.5805 - accuracy: 0.9688 - AUC: 0.9914 - val_loss: 0.5746 - val_accuracy: 0.9583 - val_AUC: 0.9991\n",
      "Epoch 110/150\n",
      "96/96 [==============================] - 0s 117us/sample - loss: 0.5806 - accuracy: 0.9688 - AUC: 0.9914 - val_loss: 0.6042 - val_accuracy: 0.9167 - val_AUC: 0.9965\n",
      "Epoch 111/150\n",
      "96/96 [==============================] - 0s 148us/sample - loss: 0.5822 - accuracy: 0.9688 - AUC: 0.9839 - val_loss: 0.5943 - val_accuracy: 0.9583 - val_AUC: 0.9974\n",
      "Epoch 112/150\n",
      "96/96 [==============================] - 0s 133us/sample - loss: 0.5786 - accuracy: 0.9688 - AUC: 0.9914 - val_loss: 0.5617 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 113/150\n",
      "96/96 [==============================] - 0s 121us/sample - loss: 0.5829 - accuracy: 0.9688 - AUC: 0.9914 - val_loss: 0.5557 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 114/150\n",
      "96/96 [==============================] - 0s 125us/sample - loss: 0.5862 - accuracy: 0.9688 - AUC: 0.9910 - val_loss: 0.5761 - val_accuracy: 0.9583 - val_AUC: 0.9991\n",
      "Epoch 115/150\n",
      "96/96 [==============================] - 0s 129us/sample - loss: 0.5786 - accuracy: 0.9792 - AUC: 0.9913 - val_loss: 0.5894 - val_accuracy: 0.9583 - val_AUC: 0.9974\n",
      "Epoch 116/150\n",
      "96/96 [==============================] - 0s 126us/sample - loss: 0.5790 - accuracy: 0.9688 - AUC: 0.9839 - val_loss: 0.6017 - val_accuracy: 0.9583 - val_AUC: 0.9974\n",
      "Epoch 117/150\n",
      "96/96 [==============================] - 0s 141us/sample - loss: 0.5806 - accuracy: 0.9688 - AUC: 0.9840 - val_loss: 0.5945 - val_accuracy: 0.9583 - val_AUC: 0.9974\n",
      "Epoch 118/150\n",
      "96/96 [==============================] - 0s 128us/sample - loss: 0.5791 - accuracy: 0.9688 - AUC: 0.9839 - val_loss: 0.5681 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 119/150\n",
      "96/96 [==============================] - 0s 113us/sample - loss: 0.5777 - accuracy: 0.9792 - AUC: 0.9913 - val_loss: 0.5538 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 120/150\n",
      "96/96 [==============================] - 0s 122us/sample - loss: 0.5866 - accuracy: 0.9583 - AUC: 0.9913 - val_loss: 0.5594 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 121/150\n",
      "96/96 [==============================] - 0s 113us/sample - loss: 0.5770 - accuracy: 0.9792 - AUC: 0.9838 - val_loss: 0.6069 - val_accuracy: 0.9583 - val_AUC: 0.9974\n",
      "Epoch 122/150\n",
      "96/96 [==============================] - 0s 107us/sample - loss: 0.5823 - accuracy: 0.9688 - AUC: 0.9839 - val_loss: 0.6331 - val_accuracy: 0.9167 - val_AUC: 0.9653\n",
      "Epoch 123/150\n",
      "96/96 [==============================] - 0s 123us/sample - loss: 0.5851 - accuracy: 0.9688 - AUC: 0.9836 - val_loss: 0.6301 - val_accuracy: 0.9167 - val_AUC: 0.9661\n",
      "Epoch 124/150\n",
      "96/96 [==============================] - 0s 120us/sample - loss: 0.5835 - accuracy: 0.9688 - AUC: 0.9839 - val_loss: 0.6156 - val_accuracy: 0.9167 - val_AUC: 0.9965\n",
      "Epoch 125/150\n",
      "96/96 [==============================] - 0s 103us/sample - loss: 0.5827 - accuracy: 0.9688 - AUC: 0.9841 - val_loss: 0.5864 - val_accuracy: 0.9583 - val_AUC: 0.9991\n",
      "Epoch 126/150\n",
      "96/96 [==============================] - 0s 123us/sample - loss: 0.5752 - accuracy: 0.9792 - AUC: 0.9840 - val_loss: 0.5735 - val_accuracy: 0.9583 - val_AUC: 0.9991\n",
      "Epoch 127/150\n",
      "96/96 [==============================] - 0s 112us/sample - loss: 0.5767 - accuracy: 0.9792 - AUC: 0.9842 - val_loss: 0.5586 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 128/150\n",
      "96/96 [==============================] - 0s 101us/sample - loss: 0.5829 - accuracy: 0.9688 - AUC: 0.9916 - val_loss: 0.5522 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 129/150\n",
      "96/96 [==============================] - 0s 121us/sample - loss: 0.5908 - accuracy: 0.9583 - AUC: 0.9912 - val_loss: 0.5702 - val_accuracy: 0.9583 - val_AUC: 0.9991\n",
      "Epoch 130/150\n",
      "96/96 [==============================] - 0s 108us/sample - loss: 0.5748 - accuracy: 0.9792 - AUC: 0.9840 - val_loss: 0.6349 - val_accuracy: 0.9167 - val_AUC: 0.9661\n",
      "Epoch 131/150\n",
      "96/96 [==============================] - 0s 167us/sample - loss: 0.5858 - accuracy: 0.9688 - AUC: 0.9762 - val_loss: 0.6354 - val_accuracy: 0.9167 - val_AUC: 0.9349\n",
      "Epoch 132/150\n",
      "96/96 [==============================] - 0s 110us/sample - loss: 0.5852 - accuracy: 0.9688 - AUC: 0.9762 - val_loss: 0.5896 - val_accuracy: 0.9583 - val_AUC: 0.9991\n",
      "Epoch 133/150\n",
      "96/96 [==============================] - 0s 122us/sample - loss: 0.5803 - accuracy: 0.9688 - AUC: 0.9840 - val_loss: 0.5600 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 134/150\n",
      "96/96 [==============================] - 0s 126us/sample - loss: 0.5855 - accuracy: 0.9688 - AUC: 0.9839 - val_loss: 0.6361 - val_accuracy: 0.9167 - val_AUC: 0.9340\n",
      "Epoch 135/150\n",
      "96/96 [==============================] - 0s 116us/sample - loss: 0.5895 - accuracy: 0.9583 - AUC: 0.9760 - val_loss: 0.6357 - val_accuracy: 0.9167 - val_AUC: 0.9340\n",
      "Epoch 136/150\n",
      "96/96 [==============================] - 0s 120us/sample - loss: 0.5881 - accuracy: 0.9583 - AUC: 0.9837 - val_loss: 0.5820 - val_accuracy: 0.9583 - val_AUC: 0.9991\n",
      "Epoch 137/150\n",
      "96/96 [==============================] - 0s 129us/sample - loss: 0.5730 - accuracy: 0.9792 - AUC: 0.9842 - val_loss: 0.5520 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 138/150\n",
      "96/96 [==============================] - 0s 114us/sample - loss: 0.5908 - accuracy: 0.9583 - AUC: 0.9833 - val_loss: 0.5524 - val_accuracy: 1.0000 - val_AUC: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/150\n",
      "96/96 [==============================] - 0s 108us/sample - loss: 0.5925 - accuracy: 0.9583 - AUC: 0.9833 - val_loss: 0.5561 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 140/150\n",
      "96/96 [==============================] - 0s 132us/sample - loss: 0.5744 - accuracy: 0.9792 - AUC: 0.9842 - val_loss: 0.6550 - val_accuracy: 0.9167 - val_AUC: 0.9323\n",
      "Epoch 141/150\n",
      "96/96 [==============================] - 0s 119us/sample - loss: 0.6025 - accuracy: 0.9479 - AUC: 0.9756 - val_loss: 0.6107 - val_accuracy: 0.9167 - val_AUC: 0.9965\n",
      "Epoch 142/150\n",
      "96/96 [==============================] - 0s 111us/sample - loss: 0.5830 - accuracy: 0.9688 - AUC: 0.9842 - val_loss: 0.5520 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 143/150\n",
      "96/96 [==============================] - 0s 117us/sample - loss: 0.5888 - accuracy: 0.9583 - AUC: 0.9836 - val_loss: 0.6044 - val_accuracy: 0.9583 - val_AUC: 0.9974\n",
      "Epoch 144/150\n",
      "96/96 [==============================] - 0s 114us/sample - loss: 0.6211 - accuracy: 0.9271 - AUC: 0.9521 - val_loss: 0.7457 - val_accuracy: 0.7917 - val_AUC: 0.8950\n",
      "Epoch 145/150\n",
      "96/96 [==============================] - 0s 106us/sample - loss: 0.8182 - accuracy: 0.7292 - AUC: 0.8333 - val_loss: 0.6783 - val_accuracy: 0.8750 - val_AUC: 0.9280\n",
      "Epoch 146/150\n",
      "96/96 [==============================] - 0s 107us/sample - loss: 0.6936 - accuracy: 0.8542 - AUC: 0.9178 - val_loss: 0.6360 - val_accuracy: 0.9167 - val_AUC: 0.9340\n",
      "Epoch 147/150\n",
      "96/96 [==============================] - 0s 111us/sample - loss: 0.6267 - accuracy: 0.9271 - AUC: 0.9520 - val_loss: 0.8843 - val_accuracy: 0.6667 - val_AUC: 0.7743\n",
      "Epoch 148/150\n",
      "96/96 [==============================] - 0s 118us/sample - loss: 0.6846 - accuracy: 0.8646 - AUC: 0.9182 - val_loss: 0.8783 - val_accuracy: 0.6667 - val_AUC: 0.7934\n",
      "Epoch 149/150\n",
      "96/96 [==============================] - 0s 107us/sample - loss: 0.6604 - accuracy: 0.8854 - AUC: 0.9346 - val_loss: 0.7380 - val_accuracy: 0.7917 - val_AUC: 0.9227\n",
      "Epoch 150/150\n",
      "96/96 [==============================] - 0s 118us/sample - loss: 0.6037 - accuracy: 0.9479 - AUC: 0.9755 - val_loss: 0.5952 - val_accuracy: 0.9583 - val_AUC: 0.9974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4024654410>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = [tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                             min_delta=1e-2,\n",
    "                                             patience=5,\n",
    "                                             verbose=1e-2)]\n",
    "model.fit(x = trainX,y = trainY, epochs= 150, batch_size = 64, validation_split= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      1.00      1.00        12\n",
      "           2       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "[[ 9  0  0]\n",
      " [ 0 12  0]\n",
      " [ 0  0  9]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(testX)\n",
    "y_test_class = np.argmax(testY,axis=1)\n",
    "y_pred_class = np.argmax(y_pred,axis=1)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test_class,y_pred_class))\n",
    "print(confusion_matrix(y_test_class,y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
